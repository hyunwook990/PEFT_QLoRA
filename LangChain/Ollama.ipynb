{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eeada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ollam list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeb22f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM:  <think>\n",
      "Okay, the user said \"안녕\" which means \"Hello\" in Korean. I need to respond appropriately.\n",
      "\n",
      "First, I should greet them back in Korean since they used Korean. So \"안녕하세요\" is the standard greeting. But maybe they want a friendly response.\n",
      "\n",
      "Wait, the user might be testing if I can handle Korean. Let me check the language settings. The user wrote in Korean, so I should respond in Korean.\n",
      "\n",
      "I should make sure to use the correct form. In Korean, \"안녕하세요\" is formal, which is appropriate for a general greeting. If it's a casual setting, it might be \"안녕\" but since I don't know the context, using the formal version is safer.\n",
      "\n",
      "Also, the user might be looking for assistance. I should ask how I can help them. So the response could be: \"안녕하세요! 무엇을 도와드릴까요?\" which translates to \"Hello! How can I help you?\"\n",
      "\n",
      "Wait, the user just said \"안녕\", so maybe they don't need anything yet. But as an assistant, it's good to offer help.\n",
      "\n",
      "Let me confirm the translation. \"안녕하세요\" is correct. Then adding a question to offer help.\n",
      "\n",
      "Yes, that's a standard response. So the answer should be in Korean: \"안녕하세요! 무엇을 도와드릴까요?\"\n",
      "\n",
      "Alternatively, maybe they want a more casual greeting. But in most contexts, especially in a professional setting, the formal greeting is better.\n",
      "\n",
      "I think that's it. Let me write the response in Korean.\n",
      "</think>\n",
      "\n",
      "안녕하세요! 무엇을 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"당신: \")\n",
    "\n",
    "    if user_input == \"종료\":\n",
    "        break\n",
    "\n",
    "    chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model=\"qwen3:4b\",\n",
    "        messages=chat_history\n",
    "    )\n",
    "\n",
    "    print(\"LLM: \", response['message']['content'])\n",
    "\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": response['message']['content']})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
