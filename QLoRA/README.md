# LLM Fine-Tuning
### 참고한 사이트: https://blog.sionic.ai/finetuning_llama 

LLM의 성능은 충분히 훌륭하다.

하지만 특화된 일을 처리하기 위해 두 가지 기법이 있다. RAG와 Finetuning이다.

### RAG, Finetuning

- Finetuning
    - 기존 LLM에 작은 데이터 세트를 추가로 학습해 특정 작업에 맞게 미세하게 조정하고 성능을 개선
    - 하지만 현재 언어 모델의 파라미터 수가 급격하게 많아져 파인튜닝이 어렵고 비용이 많이 발생한다.
    - 게다가 새로운 데이터를 학습할 때 이전의 학습 정보를 잊는 파괴적 망각(Catastrophic forgetting)의 현상 해결의 어려움이 있다.
- RAG
    - 대안으로 대두되는 RAG는 LLM의 훌륭한 성능을 유지하며 사용자의 쿼리에 효과적으로 대답할 수 있는 방법이다.

모델의 지식적인 측면을 수정하고 싶다면 RAG, 모델의 답변 형식이나 추론 방식을 수정하고 싶다면 파인튜닝이 적합하다고 한다.

쉽게 말해 내부적으로 사용한다면 RAG가 외부에 공개되는 상황이라면 파인튜닝이 좋다는 이야기로 들린다.

오픈소스 AI를 QLoRA기법으로 개인적인 데이터셋으로 파인튜닝해 허깅페이스에 배포

### 파인튜닝 기법

파인튜닝을 할 때 전체 파라미터를 수정하는 방식이 아닌 일부만 업데이트해 전자와 같은 수준의 성능을 기대할 수 있게 되었다.

- 체크포인트 기법
- PEFT (Parameter Efficient Fine-tuning)
→ 모델 전체의 파라미터가 아닌 일부를 튜닝하는 방식으로, 모델의 성능을 적은 자원으로 튜닝할 수 있도록 하는 방법
    - LoRA (Low Rank Adaptation)
    - QLoRA

### LoRA

고정 가중치를 가지고 있는 Pretrained된 모델을 기반으로 추가 학습이 가능한 Rank Decomposition 행렬을 트랜스포머 아키텍처의 각 레이어에 붙인 것이다.

→ 훈련 가능한 레이어를 추가해 새로운 데이터 세트를 학습시킨 것이다.

- Low Data Regime처럼 데이터가 적은 상황에서도 파인튜닝하기 용이하다.
- 도메인 외부의 데이터를 일반화할 때 좋은 성능을 보인다.

LoRA를 통해 학습한 가중치는 적은 양이지만 LLM 모델의 맨 윗부분을 차지하기 때문에 다른 파라미터에 얼마나 영향을 줄 지 하이퍼 파라미터를 적절히 설정해 모델의 성능을 결정할 수 있다.

### QLoRA

- LoRA의 가중치를 NormalFloat(FP4 변형)을 사용해 4비트 양자화한다.
- 큰 메모리의 GPU없이도 파인튜닝이 가능하다.
- 양자화와 distillation을 통해 모델에 저장되고 메모리에 로드되는 부담을 줄인다.

QLoRA 기법을 활용하였을 때, 일반적인 LoRA의 파인튜닝 기법보다 모델에 미치는 영향이 적다.

하지만 양자화가 인메모리 로드 부담을 절감시키는 효과를 고려한다면 가성비 대비 효과적이다.